# -*- coding: utf-8 -*-
"""0522_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PV3pL0OVxC975Bbr6eBAems2j24o3-I1
"""

!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf   #  한글폰트

"""# EDA"""

from google.colab import drive
drive.mount('/content/drive')

# library
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
plt.rc('font', family='NanumBarunGothic')
from tqdm import tqdm_notebook
from tqdm import tqdm
import re
import nltk
from pprint import pprint
from sklearn.model_selection import train_test_split
from operator import itemgetter
import warnings
warnings.filterwarnings('ignore')
import math
# from konlpy.tag import Mecab  # tok
# mecab = Mecab()
from sklearn.feature_extraction.text import TfidfVectorizer   # vec
# import fasttext
# modeling
import tensorflow as tf
from keras.models import Model, Sequential
from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Input, Dense, LSTM, Dropout
from keras.preprocessing import text, sequence
from keras.callbacks import Callback

"""-
```
- 대분류 개수 barplot
- 중분류 개수 barplot(unbalanced 함을 강조)
- 대분류끼리 자카드 계수 
- 대분류별 워드클라우드
- 토큰 길이 boxplot
- 회사별 사업목적 개수 boxplot
```
"""
## 토큰화 한 최종 데이터
data = pd.read_pickle('./data/final_data/train.pkl')
test = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/Competition/KED 대상팀/data/test.pkl')

"""# 1. 대분류끼리 자카드계수"""
data.head(1)
# data = ked_train
A = data.query('big =="A"').copy()
B = data.query('big =="B"').copy()
C = data.query('big =="C"').copy()
D = data.query('big =="D"').copy()
E = data.query('big =="E"').copy()
F = data.query('big =="F"').copy()
G = data.query('big =="G"').copy()
H = data.query('big =="H"').copy()
I = data.query('big =="I"').copy()
J = data.query('big =="J"').copy()
K = data.query('big =="K"').copy()
L = data.query('big =="L"').copy()
M = data.query('big =="M"').copy()
N = data.query('big =="N"').copy()
P = data.query('big =="P"').copy()
Q = data.query('big =="Q"').copy()
R = data.query('big =="R"').copy()
S = data.query('big =="S"').copy()

def grouping_word(tok_purpose):
  total_tok_purpose = []
  for data in tok_purpose:
    total_tok_purpose+=data
  return set(total_tok_purpose)

# 대그룹 별 토큰 모아 하나의 집합으로 만들기 (word 기준)
mydata_name = ['A', 'B', 'C','D', 'E', 'F', 'G', 'H','I', 'J','L', 'M', 'N','P', 'Q', 'R', 'S', 'K']
mydata = [A, B, C, D, E, F, G, H, I, J, K, L, M, N, P, Q, R, S]
group_mydata=[]
for dat,data_name in tqdm_notebook(zip(mydata,mydata_name)):
  locals()["group_tok_"+data_name] = grouping_word(dat['token'])
  group_mydata.append(locals()["group_tok_"+data_name])

def get_df_name(df):
    name =[x for x in globals() if globals()[x] is df][0]
    return name

# 자카드 계수 계산식
def jaccard(a,b):
    return len(a&b)/len(a|b)

# 그룹별 토큰화 데이터 list => 자카드 matrix 계산
def jaccard_matrix(mydata):
  jaccard_m= [[0] * len(mydata) for _ in range(len(mydata))]
  for i,data1 in enumerate(mydata):
    for j,data2 in enumerate(mydata):
      if i!=j:
        jaccard_val = jaccard(data1,data2)
        jaccard_m[i][j] = jaccard_val
  return jaccard_m

tok_mydata = [group_tok_A, group_tok_B, group_tok_C, group_tok_D, group_tok_E, group_tok_F, group_tok_G, group_tok_H, group_tok_I,group_tok_J,group_tok_K,group_tok_L, group_tok_M, group_tok_N,group_tok_P, group_tok_Q, group_tok_S, group_tok_R]
jm = jaccard_matrix(tok_mydata)

# cmap = "YlGnBu",
plt.figure(figsize=(20,15))
mask = np.zeros_like(jm, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

sns.heatmap(jm, 
            cmap = 'RdYlBu_r',
            xticklabels = mydata_name, yticklabels = mydata_name,
            annot=True,
            linewidths=.5,
            mask=mask, 
            cbar_kws={"shrink": .5},
            fmt='.1f')
plt.title('대분류별 Jaccard 유사도 Heatmap', fontsize=20)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.show()


"""# 2. 대분류별 워드클라우드"""
# unlist
ff = data.query('big=="R"')   # 특정 하나의 대분류만 우선 봄
token_map = ff[['company', 'token']]

plylst_song_map_unnest = np.dstack(
    (
        np.repeat(ff.company.values, list(map(len, token_map .token))), 
        np.concatenate(token_map.token.values)
    )
)

# unnested 데이터프레임 생성 : plylst_song_map
token_map  = pd.DataFrame(data = plylst_song_map_unnest[0], columns = token_map.columns)
token_map['company'] = token_map['company'].astype(str)
token_map['token'] = token_map['token'].astype(str)
token_map = token_map.query('token!="사업" & token!="판매업"')

# unnest 객체 제거
del plylst_song_map_unnest

 # 태그 별 매핑 빈도 수 저장 
from wordcloud import WordCloud
tag_cnt = token_map.groupby('token').token.count().reset_index(name = 'mapping_cnt')
tag_cnt['token'] = tag_cnt['token'].astype(str)
tag_cnt['mapping_cnt'] = tag_cnt['mapping_cnt'].astype(int)

# 빈도 수가 1000회 이상인 태그만 저장
tag_cnt = tag_cnt[tag_cnt['mapping_cnt'] >= 1000]
word_count = list(zip(tag_cnt['token'], tag_cnt['mapping_cnt']))


# plotting
path = './data/NanumSquare_acB.ttf'
wc = WordCloud(font_path = path, background_color = 'white', collocations=False, max_words = 100, width = 450, height = 450)
wc.generate_from_frequencies(dict(word_count)).to_image()

token_map.head()

plylst_tag_list_sort = pd.DataFrame()

token_sort = token_map.sort_values(by = ['company', 'token']).groupby('company').token.apply(list).reset_index(name = 'tag_list')
plylst_tag_list_sort['tag_list'] = token_sort['tag_list'].astype(str)
tag_list_plylst_cnt = plylst_tag_list_sort.groupby('tag_list').company.nunique().reset_index(name = 'token_cnt')
tag_list_plylst_cnt = tag_list_plylst_cnt.nlargest(10, 'token_cnt')

# 5. plotting
plt.figure(figsize = (11, 15))
tag_list_plylst_cnt_plot = sns.barplot(y = 'tag_list', x = 'token_cnt', data = tag_list_plylst_cnt, color = 'red')
tag_list_plylst_cnt_plot.set_title('매핑된 토큰 리스트 상위 10개')
tag_list_plylst_cnt_plot.set_xlabel('매핑된 회사 수')
tag_list_plylst_cnt_plot.set_ylabel('토큰 리스트')
plt.show()


"""# 3. 토큰 길이 boxplot"""
plt.figure(figsize=(20, 8))
sns.boxplot(x='token_len', data=data.query('token_len<2000'))
plt.title('Train data 토큰 길이의 분포', fontsize=20)
plt.xlabel(' ')
plt.xticks(fontsize=15)
plt.show()

plt.figure(figsize=(20, 8))
sns.boxplot(x='token_len', data=test.query('token_len<10000'), color='orange')
plt.title('Test data 토큰 길이의 분포', fontsize=20)
plt.xlabel(' ')
plt.xticks(fontsize=15)
plt.show()


"""# 4. 대분류별 중복 토큰"""
import nltk

total_tok_data = []
for dat in data['token']:
  total_tok_data+=dat

text = nltk.Text(total_tok_data)

common = text.vocab().most_common(14)
'판매업' in list(dict(common).keys())
cd = pd.DataFrame(common, columns=['token', 'count'])
cd['count'] = cd['count'].astype('int')

plt.figure(figsize=(15,8))
sns.barplot(data=cd, x='token', y='count', color='#000080')
plt.title('전체 데이터에서 가장 많이 등장하는 토큰', fontsize=20)
plt.xlabel(' ')
plt.ylabel('등장 횟수', fontsize=15)
plt.xticks(fontsize=15)
plt.show()


"""# 대분류 분포 plot"""
plt.figure(figsize=(15,8))
sns.countplot(data=data, x='big', color='#000080')
plt.title('Train data의 대분류 개수 분포', fontsize=20)
plt.xlabel(' ')
plt.ylabel(' ')
plt.xticks(fontsize=25)
plt.show()

plt.figure(figsize=(20,8))
sns.countplot(data=data, x='middle', color='#000080')
plt.title('Train data의 중분류 개수 분포', fontsize=20)
plt.xlabel(' ')
plt.ylabel(' ')
# plt.xticks(fontsize=25)
plt.show()














