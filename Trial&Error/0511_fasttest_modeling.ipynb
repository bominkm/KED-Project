{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0511_fasttest modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbuEy29B1uQL",
        "outputId": "21e6fbf6-9bd2-465b-acf9-ee423e6c510f"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 24.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 26.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 18.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (56.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3094600 sha256=45139b817d2fb02b93d0cc2c29f05083e819c12c17610c61bb97e0241fdc2424\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT1cXQIeFLzK",
        "outputId": "16c19242-e72a-4553-b69b-c479e99f5f35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WQIzLaW18ph"
      },
      "source": [
        "#import fasttext.util\n",
        "#fasttext.util.download_model('ko', if_exists='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ry_74ij2AYP"
      },
      "source": [
        "# library \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import fasttext\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjeizPja_N-Z"
      },
      "source": [
        "EMBEDDING_DIM = 300   # fasttext 임베딩 차원 \n",
        "\n",
        "def trash(x):\n",
        "    sw = ['부대사업','사업','부대','각호','판매업']\n",
        "    x = [word for word in x if not word in sw]\n",
        "    return x \n",
        "\n",
        "# 토큰 자르는 함수 \n",
        "def end_token(x, n):\n",
        "  if len(x)>n:\n",
        "    return x[:n]\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "# X, y train data 만들기 \n",
        "def read_corpus(path):\n",
        "    data = pd.read_pickle(path)\n",
        "    data = data.query('big not in [\"O\",\"U\",\"T\"]')  # 나중에 out 얘네들 rule base로 쳐내야함 \n",
        "\n",
        "    X = [x for x in data.iloc[:,-1].apply(trash)]   # 불용어 쳐내기 \n",
        "    X = [x for x in X.apply(end_token, n=100)] # 앞에 나온 토큰 100개로 한정 ([50:] + [:50] 시도해보기)\n",
        "\n",
        "    Y = pd.get_dummies(data['big']).values   # 대분류 get dummy로 펼치기 \n",
        "\n",
        "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=Y)\n",
        "\n",
        "    #label_enc = OneHotEncoder()    \n",
        "    #Ytrain_p = label_enc.fit_transform(np.array(Ytrain).reshape(-1,1))\n",
        "    #Ytest_p = label_enc.transform(np.array(Ytest).reshape(-1,1))    \n",
        "    return np.array(Xtrain), np.array(Xtest), np.array(Ytrain), np.array(Ytest)   # array 로 반환 \n",
        "\n",
        "\n",
        "## max_len 제한 둔 패딩 \n",
        "def pad(data, max_len=100):    \n",
        "    if max_len == 0:\n",
        "        max_len = max(len(tokens) for tokens in data)\n",
        "\n",
        "    result = []\n",
        "    for tokens in tqdm(data, desc='Padding'):\n",
        "        if len(tokens) >= max_len:  ## max_len보다 크면 그냥 max_len까지만 자르기 \n",
        "            result.append(tokens[:max_len])\n",
        "\n",
        "        else:\n",
        "            n_to_pad = max_len - len(tokens) \n",
        "            result.append(tokens + [''] * n_to_pad)\n",
        "\n",
        "    return max_len, result\n",
        "\n",
        "\n",
        "## 패딩하기 \n",
        "def preprocess(tokenized_sentences):\n",
        "    max_tokens, padded_sentences = pad(tokenized_sentences)\n",
        "    return padded_sentences\n",
        "\n",
        "### Sequence dataset 맞춤형 딥러닝 \n",
        "class Dataset(tf.keras.utils.Sequence):\n",
        "    fasttext_model_cache = {}\n",
        "    \n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x_set = x_set\n",
        "        self.y_set = y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        fasttext_model_path = 'cc.ko.300.bin' # 나중에 추가학습 시도하기 \n",
        "\n",
        "        if fasttext_model_path not in Dataset.fasttext_model_cache:\n",
        "            Dataset.fasttext_model_cache[fasttext_model_path] = fasttext.load_model(fasttext_model_path)  \n",
        "\n",
        "        self.fasttext_model = Dataset.fasttext_model_cache[fasttext_model_path]\n",
        "        #self.fasttext_model = fasttext.load_model(fasttext_model_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x_set) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        padded_sentences = self.x_set[idx * self.batch_size:(idx + 1) * self.batch_size]        \n",
        "        word_vectors = [self.get_word_vectors(padded_sentence) for padded_sentence in padded_sentences]        \n",
        "        batch_y = self.y_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        \n",
        "        return np.array(word_vectors), np.array(batch_y)\n",
        "    \n",
        "    ## word_vectors를 얻기 \n",
        "    def get_word_vectors(self, words):\n",
        "        result = []\n",
        "        for word in words:\n",
        "            if not word: \n",
        "                result.append(np.zeros((EMBEDDING_DIM,)))   # LSTM을 위한 zero padding \n",
        "            else:\n",
        "                result.append(self.fasttext_model.get_word_vector(word))\n",
        "\n",
        "        return np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdtF1pLO9Zws",
        "outputId": "07f3ddcb-6987-4f69-a677-d5194deba4a4"
      },
      "source": [
        "# if __name__ == '__main__':\n",
        "# import argparse\n",
        "\n",
        "# parser = argparse.ArgumentParser()               \n",
        "# parser.add_argument('data')\n",
        "# parser.add_argument('--batch-size', type=int, default=128)            \n",
        "# parser.add_argument('--test-batch-size', type=int)\n",
        "# parser.add_argument('--epochs', type=int, default=10)    \n",
        "# args = parser.parse_args()\n",
        "\n",
        "path = './data/0504_alltoken.pkl'\n",
        "batch_size =  128\n",
        "epoch = 10\n",
        "\n",
        "\n",
        "#### train \n",
        "train_sentences, test_sentences,train_labels,test_labels= read_corpus(path)      # X, y data 만들기 \n",
        "train_padded_sentences = preprocess(train_sentences)   # 패딩하기 \n",
        "\n",
        "train_dataset = Dataset(train_padded_sentences, train_labels, batch_size)    # Dataset 제작 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "Padding: 100%|██████████| 1262969/1262969 [00:08<00:00, 147890.49it/s]\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNOpiTOt-GpE",
        "outputId": "2df9afd9-3b68-433c-e508-6f5510721ce2"
      },
      "source": [
        "### test \n",
        "test_padded_sentences = preprocess(test_sentences)       \n",
        "test_batch_size = batch_size\n",
        "test_dataset = Dataset(test_padded_sentences, test_labels, test_batch_size)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padding: 100%|██████████| 315743/315743 [00:05<00:00, 60953.12it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ_kperFGzqg"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzNf5qmaGr2H"
      },
      "source": [
        "## Modeling function \n",
        "def build_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True), \n",
        "                                            input_shape=(None, EMBEDDING_DIM)))\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
        "    model.add(tf.keras.layers.Dense(64))\n",
        "    model.add(tf.keras.layers.Dense(17, activation='softmax'))    ## 17개의 대분류 분류\n",
        "    model.summary() \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "a5DXJL7AOsqa",
        "outputId": "f66310e1-a38c-4da1-caa9-c9da5ee8f095"
      },
      "source": [
        "model = build_model()    \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
        "model.fit(train_dataset, epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, None, 256)         439296    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 17)                1105      \n",
            "=================================================================\n",
            "Total params: 851,089\n",
            "Trainable params: 851,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "9867/9867 [==============================] - 675s 66ms/step - loss: 0.7088 - accuracy: 0.7859\n",
            "Epoch 2/10\n",
            "9867/9867 [==============================] - 664s 67ms/step - loss: 0.5242 - accuracy: 0.8366\n",
            "Epoch 3/10\n",
            "9867/9867 [==============================] - 680s 69ms/step - loss: 0.4932 - accuracy: 0.8446\n",
            "Epoch 4/10\n",
            "9867/9867 [==============================] - 660s 67ms/step - loss: 0.4718 - accuracy: 0.8508\n",
            "Epoch 5/10\n",
            "9867/9867 [==============================] - 648s 66ms/step - loss: 0.4574 - accuracy: 0.8543\n",
            "Epoch 6/10\n",
            "9867/9867 [==============================] - 650s 66ms/step - loss: 0.4396 - accuracy: 0.8586\n",
            "Epoch 7/10\n",
            "9867/9867 [==============================] - 648s 66ms/step - loss: 0.4205 - accuracy: 0.8637\n",
            "Epoch 8/10\n",
            "9867/9867 [==============================] - 649s 66ms/step - loss: 0.4030 - accuracy: 0.8686\n",
            "Epoch 9/10\n",
            "9867/9867 [==============================] - 645s 65ms/step - loss: 0.3835 - accuracy: 0.8744\n",
            "Epoch 10/10\n",
            "9867/9867 [==============================] - 648s 66ms/step - loss: 0.3668 - accuracy: 0.8793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-44bf355b3d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/classfier.{}.{}.model'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fasttext'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwfH1Gw4Kts2",
        "outputId": "6d476953-eb26-4e87-8102-2e806912d9b9"
      },
      "source": [
        "model.save('./model/classfier.{}.model'.format('fasttext'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/classfier.fasttext.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/classfier.fasttext.model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYjNcnJOZfHj",
        "outputId": "bff9d7e8-243c-415b-d892-f2bacd7d1956"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset)    \n",
        "print('test_loss', test_loss)\n",
        "print('test_accuracy', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2467/2467 [==============================] - 156s 63ms/step - loss: 0.5449 - accuracy: 0.8393\n",
            "test_loss 0.5448988676071167\n",
            "test_accuracy 0.8392806649208069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DILU8YQaPK9d"
      },
      "source": [
        "[print(i.shape, i.dtype) for i in model.inputs]\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQdQ3CaN_Myu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}